{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Cover Type Prediction \n",
    "\n",
    "**The goal of the Project**: to predict seven different cover types in four different wilderness areas of the Roosevelt National Forest of Northern Colorado with the best accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections\n",
    "\n",
    "- [1. EDA](#1)\n",
    "- [2. Feature Engineering](#2)\n",
    "- [3. Building Model](#3)\n",
    "    - [3.1 K-Nearest Neighbors](#4)\n",
    "    - [3.2 Decision Tree](#5)\n",
    "    - [3.3 Random Forest](#6)\n",
    "    - [3.4 Extra Tree](#7)\n",
    "    - [3.5 PCA](#8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the package\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint # data better printer\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
<<<<<<< HEAD
    "from sklearn.model_selection import KFold #cross validation\n",
    "\n",
    "# for feature scaling\n",
=======
    "\n",
    "# Feature Scaling\n",
>>>>>>> 567e58b63cdde1e9b59621418aa4df094f68dafc
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# tree models\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#hyperparameter search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#model validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve,confusion_matrix, accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "\n",
    "# for plot the tree\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA  <a id =\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Elevation - Elevation in meters\n",
    "- Aspect - Aspect in degrees azimuth\n",
    "- Slope - Slope in degrees\n",
    "- Horizontal_Distance_To_Hydrology - Horz Dist to nearest surface water features\n",
    "- Vertical_Distance_To_Hydrology - Vert Dist to nearest surface water features\n",
    "- Horizontal_Distance_To_Roadways - Horz Dist to nearest roadway\n",
    "- Hillshade_9am (0 to 255 index) - Hillshade index at 9am, summer solstice\n",
    "- Hillshade_Noon (0 to 255 index) - Hillshade index at noon, summer solstice\n",
    "- Hillshade_3pm (0 to 255 index) - Hillshade index at 3pm, summer solstice\n",
    "- Horizontal_Distance_To_Fire_Points - Horz Dist to nearest wildfire ignition points\n",
    "- Wilderness_Area (4 binary columns, 0 = absence or 1 = presence) - Wilderness area designation\n",
    "- Soil_Type (40 binary columns, 0 = absence or 1 = presence) - Soil Type designation\n",
    "- Cover_Type (7 types, integers 1 to 7) - Forest Cover Type designation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Check for Anomalies & Outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test= pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training dataset has 15120 entries and 56 columns with id. Dataset has no missing values and every column has a numeric (float or integer) data type.\n",
    "- Cover_Type is our target column. Wilderness_Area and Soil_Type columns might have binary values (0,1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Check Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_function(df, col_name):\n",
    "    ''' this function detects first and third quartile and interquartile range for a given column of a dataframe\n",
    "    then calculates upper and lower limits to determine outliers conservatively\n",
    "    returns the number of lower and uper limit and number of outliers respectively\n",
    "    '''\n",
    "    first_quartile = np.percentile(np.array(df[col_name].tolist()), 25)\n",
    "    third_quartile = np.percentile(np.array(df[col_name].tolist()), 75)\n",
    "    IQR = third_quartile - first_quartile\n",
    "                      \n",
    "    upper_limit = third_quartile+(3*IQR)\n",
    "    lower_limit = first_quartile-(3*IQR)\n",
    "    outlier_count = 0\n",
    "                      \n",
    "    for value in df[col_name].tolist():\n",
    "        if (value < lower_limit) | (value > upper_limit):\n",
    "            outlier_count +=1\n",
    "    return lower_limit, upper_limit, outlier_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all columns to see if there are any outliers\n",
    "for column in train.columns:\n",
    "    if outlier_function(train, column)[2] > 0:\n",
    "        print(\"There are {} outliers in {}\".format(outlier_function(train, column)[2], column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Check the important correlations between variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates pearson co-efficient for all combinations\n",
    "data_corr = train.corr()\n",
    "#get the names of all the columns\n",
    "cols=train.columns \n",
    "# Set the threshold to select only only highly correlated attributes\n",
    "threshold = 0.5\n",
    "# List of pairs along with correlation above threshold\n",
    "corr_list = []\n",
    "\n",
    "for i in range(len(data_corr)):\n",
    "    for j in range(i+1,len(data_corr)):\n",
    "        if (data_corr.iloc[i,j] >= threshold and data_corr.iloc[i,j] < 1) or (data_corr.iloc[i,j] < 0 and data_corr.iloc[i,j] <= -threshold):\n",
    "            corr_list.append([data_corr.iloc[i,j],i,j]) #store correlation and columns index\n",
    "\n",
    "#Sort to show higher ones first            \n",
    "sorted_corr_list = sorted(corr_list,key=lambda x: -abs(x[0]))\n",
    "\n",
    "#Print correlations and column names\n",
    "for v,i,j in sorted_corr_list:\n",
    "    print (\"%s and %s = %.2f\" % (cols[i],cols[j],v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Feature: Wilderness_Area, Soil_Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_check=[column for column in train.columns if (\"Wilderness\" in column)|(\"Soil\" in column)]\n",
    "# variables in each feature\n",
    "print('Feature \\t   Unique Count \\t Values', end='\\n'+'-'*50 + '\\n')\n",
    "for column in columns_check:\n",
    "    uniques = sorted(train[column].unique())\n",
    "    print('{0:20s} {1:5d}\\t\\t'.format(column, len(uniques)), uniques[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wilderness_Area & Soil_Type are binary variables, Soil_Type7 & Soil_Type15 only include value of 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Feature: cover_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.countplot(x='Cover_Type',data=train)\n",
    "\n",
    "# set title, legends and labels\n",
    "plt.xlabel(\"Cover_Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Cover_Types\", size=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of cover types shows perfect uniform distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Feature: Cover_Type & Wilderness_Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reverse One hot encoding to get a column for the Wilderness area\n",
    "train.loc[train[\"Wilderness_Area1\"]==1,\"Wilderness_Area\"] = \"Wilderness Area 1\"\n",
    "train.loc[train[\"Wilderness_Area2\"]==1,\"Wilderness_Area\"] = \"Wilderness Area 2\"\n",
    "train.loc[train[\"Wilderness_Area3\"]==1,\"Wilderness_Area\"] = \"Wilderness Area 3\"\n",
    "train.loc[train[\"Wilderness_Area4\"]==1,\"Wilderness_Area\"] = \"Wilderness Area 4\"\n",
    "## plot\n",
    "plt.figure(figsize=(15,6))   \n",
    "order = [\"Wilderness Area 1\",\"Wilderness Area 2\",\"Wilderness Area 3\",\"Wilderness Area 4\"]\n",
    "ax = sns.countplot(x= \"Wilderness_Area\", hue = \"Cover_Type\", data = train, order=order)\n",
    "ax.set_xlabel(\"Wilderness Area\",fontsize=12)\n",
    "ax.set_ylabel(\"Count\",fontsize=12)\n",
    "plt.legend(title=\"Cover Type\", loc='upper left',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some cover types only belong specific wilderness areas, in this case wilderness areas could be a significant variables in the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Feature: Other continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(y=train['Horizontal_Distance_To_Roadways'], x=train['Cover_Type'])\n",
    "ax.set_title('Horizontal Distance To Roadways Distribution For Different Cover Type',fontsize=12)\n",
    "ax.set_xlabel(\"Cover Type\",fontsize=12)\n",
    "ax.set_ylabel(\"Horizontal Distance To Roadways\",fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.boxplot(y=train['Aspect'], x=train['Cover_Type'])\n",
    "ax.set_title('Aspect Distribution For Different Cover Type',fontsize=12)\n",
    "ax.set_xlabel(\"Cover Type\",fontsize=12)\n",
    "ax.set_ylabel(\"Aspect\",fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cover Type 4 \"Cottonwood/Willow\" has long tail distribution for \"Aspect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=train['Elevation'], x=train['Cover_Type'])\n",
    "ax.set_title('Elevation Distribution For Different Cover Type',fontsize=12)\n",
    "ax.set_xlabel(\"Cover Type\",fontsize=12)\n",
    "ax.set_ylabel(\"Elevation\",fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering <a id =\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1  Euclidian distance to Hydrology\n",
    "\n",
    "Combine Horizontal_Distance_To_Hydrology & Vertical_Distance_To_Hydrology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Euclidian_Distance_To_Hydrology']= (train['Horizontal_Distance_To_Hydrology']**2 + train['Vertical_Distance_To_Hydrology']**2)**0.5\n",
    "display(train.head())\n",
    "sns.boxplot(y=train[\"Euclidian_Distance_To_Hydrology\"], x=train[\"Cover_Type\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(28,13), dpi= 80)\n",
    "plt.scatter(train.Elevation, train.Horizontal_Distance_To_Hydrology, c=train.Cover_Type)\n",
    "plt.ylabel('Horizontal_Distance_To_Hydrology', fontsize='x-large')\n",
    "plt.xlabel('Elevation', fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The association between Horizontal Distance to Hydrology and Elevation shows a potentially usefull feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 Power transformation of Elevation\n",
    "\n",
    "As elevation is already a top predictor of cover types, a power transformation of elevation can provide even further distinction between cover types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sq_Elevation'] = np.power(train['Elevation'],1.5)\n",
    "display(train.head())\n",
    "sns.boxplot(y=train[\"sq_Elevation\"], x=train[\"Cover_Type\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.3 Aspect Transformations\n",
    "Aspect is in terms of degrees azimuth. This degrees is flattened to be on a scale between 0 and 360, but repersenting the data in this manner create an discontinuity at 0 and 360 degrees which are supposed to be one and the same. Thus, we transformed 'Aspect' to help reconcile this by shifting the values by 180 degress such that the degree of 0 and 360 becomes 180. Then, we use the *arctan* of the transformed aspect to differentiate between similar aspect while keeping the range between -ℼ/2 and ℼ/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['norm_aspect'] = train.Aspect.map(lambda x: x-180 if x > 180 else x+180)\n",
    "train['atan_aspect'] = np.arctan(train.norm_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=train[\"norm_aspect\"], x=train[\"Cover_Type\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=train[\"atan_aspect\"], x=train[\"Cover_Type\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding all normalizations and transformations in one workflow, including distance alterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df, version=0):\n",
    "    df_n = df.copy()\n",
    "    df_n.drop(columns=['Id'],inplace=True)\n",
    "    df_n = df_n.astype({c:'bool' for c in df_n.columns if \"Soil_Type\" in c or \"Wilderness_Area\" in c})\n",
<<<<<<< HEAD
    "    if version >= 1: \n",
    "        col_normalize = ['Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology', \n",
=======
    "    \n",
    "    if version >= 1: # \n",
    "        col_normalize = ['Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology', \n",
>>>>>>> 567e58b63cdde1e9b59621418aa4df094f68dafc
    "                     'Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points',\n",
    "                     'Horizontal_Distance_To_Roadways']\n",
    "        df_n['log_Horizontal_Distance_To_Roadways'] = np.log(df_n['Horizontal_Distance_To_Roadways']+1)\n",
    "        df_n['log_Horizontal_Distance_To_Fire_Points'] = np.log(df_n['Horizontal_Distance_To_Fire_Points']+1)\n",
    "        df_n[col_normalize] = normalize(df_n[col_normalize])\n",
    "        df_n.drop(columns=['Soil_Type7'],inplace=True)\n",
    "        \n",
    "    if version >= 2:\n",
    "        df_n['sq_Elevation'] = np.power(df['Elevation'],1.5)\n",
    "        df_n.drop(columns='Aspect',inplace=True)\n",
<<<<<<< HEAD
    "        df_n['norm_aspect'] = df.Aspect.map(lambda x: x-180 if x > 180 else x+180) # np.abs(df.Aspect - 180)\n",
    "    if version >= 3: # 0.9104497354497356\n",
=======
    "        df_n['norm_aspect'] = df.Aspect.map(lambda x: x-180 if x > 180 else x+180)\n",
    "        df_n['atan_aspect'] = np.arctan(df_n.norm_aspect)\n",
    "        \n",
    "    if version >= 3:\n",
>>>>>>> 567e58b63cdde1e9b59621418aa4df094f68dafc
    "        df_n['Vertical_Distance_To_Hydrology'] = np.abs(df_n.Vertical_Distance_To_Hydrology)\n",
    "        df_n['E-VH'] = df.Elevation - df.Vertical_Distance_To_Hydrology * .9 \n",
    "        df_n['E-HH'] = df.Elevation - df.Horizontal_Distance_To_Hydrology * .5\n",
    "        \n",
<<<<<<< HEAD
    "        \n",
    "        df_n['F+R'] = (df.Horizontal_Distance_To_Fire_Points + df.Horizontal_Distance_To_Roadways) ** 2\n",
    "        df_n['F+H'] = (df.Horizontal_Distance_To_Fire_Points + df.Horizontal_Distance_To_Hydrology) ** 0.3\n",
    "        df_n['H+R'] = (df.Horizontal_Distance_To_Hydrology + df.Horizontal_Distance_To_Roadways)\n",
    "        \n",
    "        df_n['abs_H-R'] = (np.abs(df.Horizontal_Distance_To_Hydrology - df.Horizontal_Distance_To_Roadways)) \n",
    "        df_n['abs_H-F'] = (np.abs(df.Horizontal_Distance_To_Hydrology - df.Horizontal_Distance_To_Fire_Points)) \n",
    "        df_n['abs_F-R'] = (np.abs(df.Horizontal_Distance_To_Fire_Points - df.Horizontal_Distance_To_Roadways)) \n",
    "    return df_n\n"
=======
    "        df_n['F+R'] = (df.Horizontal_Distance_To_Fire_Points + df.Horizontal_Distance_To_Roadways) ** 2\n",
    "        df_n['F+H'] = (df.Horizontal_Distance_To_Fire_Points + df.Horizontal_Distance_To_Hydrology) ** 0.3\n",
    "        df_n['H+R'] = (df.Horizontal_Distance_To_Hydrology + df.Horizontal_Distance_To_Roadways)\n",
    "        \n",
    "        df_n['abs_H-R'] = (np.abs(df.Horizontal_Distance_To_Hydrology - df.Horizontal_Distance_To_Roadways)) \n",
    "        df_n['abs_H-F'] = (np.abs(df.Horizontal_Distance_To_Hydrology - df.Horizontal_Distance_To_Fire_Points)) \n",
    "        df_n['abs_F-R'] = (np.abs(df.Horizontal_Distance_To_Fire_Points - df.Horizontal_Distance_To_Roadways)) \n",
    "        \n",
    "    return df_n"
>>>>>>> 567e58b63cdde1e9b59621418aa4df094f68dafc
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_c=pipeline(df_train, version=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_c.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building Model <a id =\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate labels from features in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature=train.drop(['Cover_Type','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology'],axis=1)\n",
    "train_label=train['Cover_Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training set as training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(train_feature, train_label, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 K-Nearest Neighbors <a id =\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Feature Scaling\n",
    "\n",
    "> KNN chooses the k closest neighbors and then based on these neighbors, assigns a class (for classification problems) or predicts a value (for regression problems) for a new observation. K-Means clusters the similar points together. The similarity here is defined by the distance between the points. Lesser the distance between the points, more is the similarity and vice versa. **Here feature scaling helps to weigh all the features equally.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1.1 First Rescaling uses Standard Scaling \n",
    "\n",
    ">One approach to data scaling involves calculating the mean and standard deviation of each variable and using these values to scale the values to have a mean of zero and a standard deviation of one, a so-called “standard normal” probability distribution. This process is called standardization and is most useful when input variables have a Gaussian probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_dev_scaled = sc.fit_transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best number of neighbors\n",
    "n_neighbors=np.arange(1,9)\n",
    "train_score = np.empty(len(n_neighbors)) \n",
    "dev_score = np.empty(len(n_neighbors)) \n",
    "\n",
    "# iterate the list\n",
    "for index,neighbor in enumerate(n_neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbor) \n",
    "    knn.fit(X_train_scaled, y_train) \n",
    "    # compute training and test data accuracy\n",
    "    train_score[index] = knn.score(X_train_scaled, y_train) \n",
    "    dev_score[index] = knn.score(X_dev_scaled, y_dev) \n",
    "\n",
    "# Generate plot \n",
    "plt.figure(figsize=(12,5))\n",
    "p = sns.lineplot(n_neighbors,dev_score,marker='*',label='Dev Score')\n",
    "p = sns.lineplot(n_neighbors,train_score,marker='o',label='Test Score')   \n",
    "plt.legend() \n",
    "plt.xlabel('n_neighbors') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dev_score = max(dev_score)\n",
    "max_dev_score_index=[i for i, v in enumerate(dev_score) if v == max_dev_score]\n",
    "print('Max test score {} % and k = {}'.format(max_dev_score*100,list(map(lambda x: x+1, max_dev_score_index))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1.2 Using Robust Scaling to handle the presences of outliers using Robust Scaling to handle the presences of outliers\n",
    "\n",
    "> One approach to standardizing input variables in the presence of outliers is to ignore the outliers from the calculation of the mean and standard deviation, then use the calculated values to scale the variable. This is called robust standardization or robust data scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustsc = RobustScaler()\n",
    "X_train_scaled_r = robustsc.fit_transform(X_train)\n",
    "X_dev_scaled_r = robustsc.fit_transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best number of neighbors\n",
    "n_neighbors=np.arange(1,9)\n",
    "train_score = np.empty(len(n_neighbors)) \n",
    "dev_score = np.empty(len(n_neighbors)) \n",
    "\n",
    "# iterate the list\n",
    "for index,neighbor in enumerate(n_neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbor) \n",
    "    knn.fit(X_train_scaled, y_train) \n",
    "    # compute training and test data accuracy\n",
    "    train_score[index] = knn.score(X_train_scaled_r, y_train) \n",
    "    dev_score[index] = knn.score(X_dev_scaled_r, y_dev) \n",
    "\n",
    "# Generate plot \n",
    "plt.figure(figsize=(12,5))\n",
    "p = sns.lineplot(n_neighbors,dev_score,marker='*',label='Dev Score')\n",
    "p = sns.lineplot(n_neighbors,train_score,marker='o',label='Test Score')   \n",
    "plt.legend() \n",
    "plt.xlabel('n_neighbors') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dev_score = max(dev_score)\n",
    "max_dev_score_index=[i for i, v in enumerate(dev_score) if v == max_dev_score]\n",
    "print('Max test score {} % and k = {}'.format(max_dev_score*100,list(map(lambda x: x+1, max_dev_score_index))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN achieve the best performance, accuracy of 81.08%  with K = 1\n",
    "- With RobustScaler, the accuracy is under Standard Scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Decision Tree  <a id =\"5\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for fitting trees of various depths on the training data using cross-validation\n",
    "def run_cross_validation_on_trees(X, y, tree_depths, cv=5, scoring='accuracy'):\n",
    "    cv_scores_list = []\n",
    "    cv_scores_std = []\n",
    "    cv_scores_mean = []\n",
    "    accuracy_scores = []\n",
    "    for depth in tree_depths:\n",
    "        tree_model = DecisionTreeClassifier(max_depth=depth)\n",
    "        cv_scores = cross_val_score(tree_model, X, y, cv=cv, scoring=scoring)\n",
    "        cv_scores_list.append(cv_scores)\n",
    "        cv_scores_mean.append(cv_scores.mean())\n",
    "        cv_scores_std.append(cv_scores.std())\n",
    "        accuracy_scores.append(tree_model.fit(X, y).score(X, y))\n",
    "    cv_scores_mean = np.array(cv_scores_mean)\n",
    "    cv_scores_std = np.array(cv_scores_std)\n",
    "    accuracy_scores = np.array(accuracy_scores)\n",
    "    return cv_scores_mean, cv_scores_std, accuracy_scores\n",
    "  \n",
    "# function for plotting cross-validation results\n",
    "def plot_cross_validation_on_trees(depths, cv_scores_mean, cv_scores_std, accuracy_scores, title):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15,5))\n",
    "    ax.plot(depths, cv_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)\n",
    "    ax.fill_between(depths, cv_scores_mean-2*cv_scores_std, cv_scores_mean+2*cv_scores_std, alpha=0.2)\n",
    "    ylim = plt.ylim()\n",
    "    ax.plot(depths, accuracy_scores, '-*', label='train accuracy', alpha=0.9)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('Tree depth', fontsize=14)\n",
    "    ax.set_ylabel('Accuracy', fontsize=14)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xticks(depths)\n",
    "    ax.legend()\n",
    "\n",
    "# fitting trees of depth 1 to 24\n",
    "sm_tree_depths = range(1,25)\n",
    "sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores = run_cross_validation_on_trees(X_train, y_train, sm_tree_depths)\n",
    "\n",
    "# plotting accuracy\n",
    "plot_cross_validation_on_trees(sm_tree_depths, sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores, \n",
    "                               'Accuracy per decision tree depth on training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_max = sm_cv_scores_mean.argmax()\n",
    "sm_best_tree_depth = sm_tree_depths[idx_max]\n",
    "sm_best_tree_cv_score = sm_cv_scores_mean[idx_max]\n",
    "sm_best_tree_cv_score_std = sm_cv_scores_std[idx_max]\n",
    "print('The depth-{} tree achieves the best mean cross-validation accuracy {} +/- {}% on training dataset'.format(\n",
    "      sm_best_tree_depth, round(sm_best_tree_cv_score*100,5), round(sm_best_tree_cv_score_std*100, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Random Forest <a id =\"6\"></a>\n",
    "\n",
    "> The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree.\n",
    "\n",
    "\n",
    ">Making predictions with a Random Forest: get a prediction from every tree (summing up to N predictions) and then obtain an overall, aggregated prediction. Bootstrapping the data and then using an aggregate to make a prediction is called Bagging, and how this prediction is made depends on the kind of problem we are facing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Create a random forest with 100 tress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "forest= RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "forest=forest.fit(X_train, y_train)\n",
    "y_pred=forest.predict(X_dev)\n",
    "print(\"Accuracy:\", accuracy_score(y_pred, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Important Features\n",
    "feature_importances_df = pd.DataFrame({\"feature\": list(X_train.columns), \n",
    "                                       \"importance\": forest.feature_importances_}\n",
    "                                     ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "# Display\n",
    "feature_importances_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Hyperparameter Tuning - Grid Search and Random Search\n",
    "\n",
    "In the case of a random forest, **hyperparameters include the number of decision trees in the forest and the number of features considered by each tree when splitting a node.** (The parameters of a random forest are the variables and thresholds used to split each node learned during training). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(forest.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2.1 Hyperparameter Tuning - Random Search\n",
    "\n",
    "set up a grid of hyperparameter values and select random combinations to train the model and score. The number of search iterations is set based on time/resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On each iteration, the algorithm will choose a difference combination of the features. However, the benefit of a random search is that we are not trying every combination, but selecting at random to sample a wide range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "def random_tune(forest):\n",
    "    random_grid = {\n",
    "        'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "    # Random search of parameters, using 10 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = forest, \n",
    "                                   param_distributions = random_grid, \n",
    "                                   n_iter = 100,  # controls the number of different combinations to try\n",
    "                                   cv = 10, # number of folds to use for cross validation\n",
    "                                   verbose=2, \n",
    "                                   random_state=42, \n",
    "                                   n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    return rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()\n",
    "rf_random_dict = random_tune(forest)\n",
    "rf_random_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest= RandomForestClassifier(n_estimators=rf_random_dict['n_estimators'], \n",
    "                               min_samples_split = rf_random_dict['min_samples_split'],\n",
    "                               min_samples_leaf = rf_random_dict['min_samples_leaf'],\n",
    "                               max_features = rf_random_dict['max_features'],\n",
    "                               bootstrap = rf_random_dict['bootstrap'],\n",
    "                               max_depth=rf_random_dict['max_depth'],)\n",
    "forest=forest.fit(X_train, y_train)\n",
    "y_pred=forest.predict(X_dev)\n",
    "print(\"After random search to find the best hypeparameters, random forest model achieves: \", accuracy_score(y_pred, y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2.1 Hyperparameter Tuning - Grid Search\n",
    "\n",
    "set up a grid of hyperparameter values and for each combination, train a model and score on the validation data. In this approach, every single combination of hyperparameters values is tried which can be very inefficient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the grid grid to search for best hyperparameters\n",
    "def grid_tune(forest):\n",
    "    param_grid = {\n",
    "        'bootstrap': [True],\n",
    "        'max_depth': [80, 90, 100, 110],\n",
    "        'max_features': [2, 3],\n",
    "        'min_samples_leaf': [3, 4, 5],\n",
    "        'min_samples_split': [8, 10, 12],\n",
    "        'n_estimators': [100, 200, 300, 1000]\n",
    "        }\n",
    "    # Random search of parameters, using 10 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    f_grid = GridSearchCV(estimator = forest, \n",
    "                                   param_grid = param_grid,\n",
    "                                   cv = 10, # number of folds to use for cross validation\n",
    "                                   n_jobs = -1,\n",
    "                                   verbose = 2)\n",
    "    # Fit the grid search model\n",
    "    f_grid.fit(X_train, y_train)\n",
    "    return rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()\n",
    "rf_grid_dict = random_tune(forest)\n",
    "rf_grid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest= RandomForestClassifier(n_estimators=rf_grid_dict['n_estimators'], \n",
    "                               max_depth = rf_grid_dict['max_depth'],\n",
    "                               min_samples_split = rf_grid_dict['min_samples_split'],\n",
    "                               min_samples_leaf = rf_grid_dict['min_samples_leaf'],\n",
    "                               max_features = rf_grid_dict['max_features'],\n",
    "                               bootstrap = rf_grid_dict['bootstrap'])\n",
    "forest=forest.fit(X_train, y_train)\n",
    "y_pred=forest.predict(X_dev)\n",
    "print(\"After grid search to find the best hypeparameters, random forest model achieves:\", accuracy_score(y_pred, y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Extra tree  <a id =\"7\"></a>\n",
    "\n",
    "- Random forest develop each decision tree from a bootstrap sample of the training dataset, the Extra Trees algorithm fits each decision tree on the whole training dataset. (Extra Trees use the whole original sample. In the Extra Trees sklearn implementation there is an optional parameter that allows users to bootstrap replicas, but by default, it uses the entire input sample.)\n",
    "\n",
    "- In order to split nodes, the Extra Trees algorithm will randomly sample the features at each split point of a decision tree. Unlike random forest, which uses a greedy algorithm to select an optimal split point, the Extra Trees algorithm selects a split point at random.\n",
    "\n",
    "- The Extra Trees algorithm is faster. This algorithm saves time because the whole procedure is the same, but it randomly chooses the split point and does not calculate the optimal one.\n",
    "\n",
    "\n",
    "**Extra tree  does not bootstrap observations (meaning it samples without replacement), and nodes are split on random splits, not best splits.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = ExtraTreesClassifier()\n",
    "et_random_dict = random_tune(forest)\n",
    "et_random_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extratree = ExtraTreesClassifier(n_estimators = et_random_dict['n_estimators'], \n",
    "                               min_samples_split = et_random_dict['min_samples_split'],\n",
    "                               min_samples_leaf = et_random_dict['min_samples_leaf'],\n",
    "                               max_features = et_random_dict['max_features'],\n",
    "                               bootstrap = et_random_dict['bootstrap'],\n",
    "                               max_depth = et_random_dict['max_depth'],)\n",
    "Extratree=Extratree.fit(X_train, y_train)\n",
    "y_pred=Extratree.predict(X_dev)\n",
    "\n",
    "print(\"After random search to find the best hypeparameters, extra tree model achieves: \", accuracy_score(y_pred, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = ExtraTreesClassifier()\n",
    "et_grid_dict = grid_tune(forest)\n",
    "et_grid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extratree = ExtraTreesClassifier(n_estimators = et_grid_dict['n_estimators'], \n",
    "                               max_depth = et_grid_dict['max_depth'],\n",
    "                               min_samples_split = et_grid_dict['min_samples_split'],\n",
    "                               min_samples_leaf = et_grid_dict['min_samples_leaf'],\n",
    "                               max_features = et_grid_dict['max_features'],\n",
    "                               bootstrap = et_grid_dict['bootstrap'])\n",
    "ExtraTreesClassifier=forest.fit(X_train, y_train)\n",
    "y_pred=ExtraTreesClassifier.predict(X_dev)\n",
    "print(\"After grid search to find the best hypeparameters, extra tree model achieves:\", accuracy_score(y_pred, y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 PCA   <a id =\"8\"></a>\n",
    "\n",
    "Principal component analysis is a statistical technique to convert **high dimensional data to low dimensional data** by selecting the most important features that capture maximum information about the dataset. The features are selected on the basis of variance that they cause in the output. The feature that causes highest variance is the first principal component. The feature that is responsible for second highest variance is considered the second principal component, and so on. It is important to mention that principal components do not have any correlation with each other.\n",
    "\n",
    "\n",
    "### 3.4.1 Compute covariance matrix\n",
    "\n",
    "A covariance matrix expresses the correlation between the different features in the data set. It is essential to identify heavily dependent variables because they contain biased and redundant information which reduces the overall performance of the model. The below code snippet computes the covariance matrix for the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec = np.mean(X_train_scaled, axis=0)\n",
    "cov_mat = (X_train_scaled - mean_vec).T.dot((X_train_scaled - mean_vec)) / (X_train_scaled.shape[0]-1)\n",
    "print('Covariance matrix n%s' %cov_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Calculate eigenvectors and eigenvalues\n",
    "\n",
    "eigenvectors and eigenvalues are calculated which basically compute the Principal Components of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating eigenvectors and eigenvalues on covariance matrix\n",
    "cov_mat = np.cov(X_train_scaled.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "print('Eigenvectors n%s' %eig_vecs)\n",
    "print('nEigenvalues n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Compute the feature vector \n",
    "\n",
    "In this step, we rearrange the eigenvalues in descending order. This represents the significance of the principal components in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    pprint(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 Use the PCA() function to reduce the dimensionality of the data set\n",
    "\n",
    "The below code snippet uses the pre-defined PCA() function provided by the sklearn package in order to transform the data. The n_components parameter denotes the number of Principal Components we want to fit your data with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(15)\n",
    "X_train_pca =pca.fit_transform(X_train)\n",
    "X_dev_pca = pca.transform(X_dev)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that first principal component is responsible for 72.28% variance. Similarly, the second principal component causes 22.48% variance in the dataset. Collectively we can say that (72.28% + 22.48) 94.76% percent of the classification information contained in the feature set is captured by the first two principal components.\n",
    "\n",
    "Try to use 1 principal component to train our algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2 = PCA(n_components=2)\n",
    "X_train_pca_2 = pca_2.fit_transform(X_train)\n",
    "X_dev_pca_2 = pca_2.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "classifier.fit(X_train_pca_2, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_dev_pca_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_dev, y_pred)"
   ]
<<<<<<< Updated upstream
=======
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Performance <a id =\"100\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set general plt settings\n",
    "cs = ['#EE6666', '#7abf0a', '#9988DD',\n",
    "      '#EECC55', '#88BB44', '#3a32d1',\n",
    "      '#391306', '#3388BB', '#1DC690']\n",
    "colors = cycler('color', cs)\n",
    "plt.rc('axes', facecolor='#E6E6E6', edgecolor='none',\n",
    "       axisbelow=True, grid=True, prop_cycle=colors)\n",
    "plt.rc('grid', color='w', linestyle='solid')\n",
    "plt.rc('xtick', direction='out', color='w')\n",
    "plt.rc('ytick', direction='out', color='w')\n",
    "plt.rc('patch', edgecolor='#E6E6E6')\n",
    "plt.rc('lines', linewidth=2)\n",
    "\n",
    "def set_ax_settings(ax, y_label, x_label='Feature Version', label_size='x-large', label_color='limegreen'):\n",
    "    ax.set_xticks([0,1,2,3])\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.xaxis.label.set_color(label_color)\n",
    "    ax.xaxis.label.set_size(label_size)\n",
    "    ax.yaxis.label.set_color(label_color)\n",
    "    ax.yaxis.label.set_size(label_size)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_excel('model_results.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy <a id =\"101\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(20,10))\n",
    "\n",
    "for i, model_name in enumerate(result_df.model.unique()):\n",
    "    df_r = result_df[result_df.model == model_name]\n",
    "    ax.plot(df_r.version, df_r.acc, label='{} training CV accuracy'.format(model_name), c=cs[i])\n",
    "    ax.plot(df_r.version, df_r.k_acc, linestyle='--', dashes=(5,5) , label='{} test accuracy'.format(model_name), c=cs[i])\n",
    "    \n",
    "set_ax_settings(ax, 'Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Taken <a id =\"102\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(20,10))\n",
    "\n",
    "for i, model_name in enumerate(result_df.model.unique()):\n",
    "    df_r = result_df[result_df.model == model_name]\n",
    "    ax.plot(df_r.version, df_r.time, label='{} - time taken'.format(model_name), c=cs[i])\n",
    "    \n",
    "set_ax_settings(ax, 'Time Taken (sec)')\n",
    "plt.show()"
   ]
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
